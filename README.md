# LangChain RAG API Demo

This project demonstrates a simple Retrieval-Augmented Generation (RAG) application using LangChain, Google Gemini, and Streamlit. It allows users to upload a text file, ask a question about its content, and receive an answer generated by an LLM with retrieval support.

## Project Structure

- **backend.py**: Contains the core logic for processing uploaded files, splitting text, generating embeddings, creating a vector store, and querying the LLM. All RAG operations are handled here.
- **api.py**: Implements a FastAPI backend that exposes an HTTP endpoint (`/generate-response`). It receives file uploads and user queries from the frontend, calls the backend logic, and returns the result as JSON.
- **streamlit.py**: Provides a user-friendly web interface for uploading files, entering questions, and displaying answers. It communicates with the FastAPI backend via HTTP requests.

## Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/langchain-rag-api.git
cd langchain-rag-api
```

### 2. Install Dependencies

It is recommended to use a virtual environment:

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Set Up API Keys

- You will need a **Google API Key** for Gemini and embeddings.
- You can obtain one from the [Google AI Studio](https://aistudio.google.com/app/apikey).
- You do **not** need a LangSmith API key unless you want experiment tracking (see warning section below).

### 4. Run the FastAPI Backend

```bash
uvicorn api:app --reload
```

This will start the backend at `http://localhost:8000`.

### 5. Run the Streamlit Frontend

In a new terminal (with the virtual environment activated):

```bash
streamlit run streamlit.py
```

This will start the frontend at `http://localhost:8501`.

## Usage

1. Open the Streamlit app in your browser (`http://localhost:8501`).
2. Upload a `.txt` file containing the content you want to query.
3. Enter your question and your Google API key.
4. Click **Submit**. The answer will appear below.

## Troubleshooting

- **File content not updating?**
  - Make sure you upload a file with a different name or refresh the app if you see old results.
  - The app now reads file content immediately to avoid caching issues.
- **API key errors?**
  - Ensure you are using a valid Google API key for Gemini.
- **LangSmith warning?**
  - You may see a warning about a missing LangSmith API key. This is safe to ignore unless you want to use LangSmith experiment tracking.
- **CORS errors?**
  - The FastAPI backend is configured to allow requests from any origin. If you deploy, restrict this for security.

## File Descriptions

- **backend.py**: Implements the `generate_response` function, which handles all RAG logic (splitting, embedding, vector store, LLM, and retrieval).
- **api.py**: FastAPI app that exposes the `/generate-response` endpoint. Receives file uploads and queries, calls `generate_response`, and returns the answer.
- **streamlit.py**: Streamlit web app for user interaction. Handles file upload, question input, API key input, and displays the answer by calling the backend API.

## License

MIT
